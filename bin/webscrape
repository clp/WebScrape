#! /usr/bin/env perl

use strict;
use warnings;

use Getopt::Long;

our $VERSION = '0.01';

my $prog = $0;
$prog =~ s{\A.*/}{};    # strip leading path, if any

my $url;

unless (
    GetOptions(
        'url=s' => \$url,
    )
    )
{
    die usage();
}
unless ($url) {
    die "$prog died: No url found on command line.\n\n", usage();
}



use WWW::Mechanize;
use HTTP::Cookies;
my $outfile = "out.html";
my $mech = WWW::Mechanize->new();
my $cookie_jar = HTTP::Cookies->new(
  file => "$ENV{'HOME'}/perl.lwp.cookies.dat",
  autosave => 1,
  );
$mech->cookie_jar( $cookie_jar );
$mech->agent_alias( 'Linux Mozilla' );
$mech->get($url);


my $output_page = $mech->content();
my $out;
open($out, '>', $outfile);
print {$out} "$output_page";
close($out);


exit 1;




sub usage {
    return <<"eousage";
Usage:
  $prog -u url

$prog requests a web site to return a page, and displays the HTML
data found there.

Options to control the query

-url string              The specific http address to query.
                         Required.
eousage
}



=begin notes

Notes.

1.  Use agent_alias() to get response from some sites that prohibit
robots.

2.  The cookie_jar can be used when a site requires a login.

3.  WWW::Mechanize might not be a good solution to use for pages 
with Javascript.


=end notes

=cut

